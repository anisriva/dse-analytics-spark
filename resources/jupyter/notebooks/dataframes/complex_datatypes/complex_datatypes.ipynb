{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Complex Data Types in Spark SQL\n",
    "In this notebook we're going to go through some data transformation examples using Spark SQL. Spark SQL supports many built-in transformation functions in the module pyspark.sql.functions therefore we will start off by importing that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.appName('complex').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method for creating df out of json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_DF(json, schema = None):\n",
    "    reader = spark.read\n",
    "    if schema:\n",
    "        reader.schema(schema)\n",
    "    return reader.json(spark.sparkContext.parallelize([json]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting from nested columns - Dots (\".\") can be used to access nested columns for structs and maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- a: struct (nullable = true)\n",
      " |    |-- b: integer (nullable = true)\n",
      "\n",
      "+---+\n",
      "|  a|\n",
      "+---+\n",
      "|{1}|\n",
      "+---+\n",
      "\n",
      "+---+\n",
      "|  b|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType().add(\"a\", StructType().add(\"b\", IntegerType()))\n",
    "\n",
    "json_data = \"\"\"\n",
    "{\n",
    "  \"a\": {\n",
    "     \"b\": 1\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "json_df = json_to_DF(json_data, schema)\n",
    "json_df.printSchema()\n",
    "json_df.show()\n",
    "json_df.select(\"a.b\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a map type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- a: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: integer (valueContainsNull = true)\n",
      "\n",
      "+--------+\n",
      "|       a|\n",
      "+--------+\n",
      "|{b -> 1}|\n",
      "+--------+\n",
      "\n",
      "+---+\n",
      "|  b|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType().add(\"a\", MapType(StringType(), IntegerType()))\n",
    "json_map_df = json_to_DF(json_data, schema)\n",
    "json_map_df.printSchema()\n",
    "json_map_df.show()\n",
    "json_map_df.select(\"a.b\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening structs - A star (\"*\") can be used to select all of the subfields in a struct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  b|  c|\n",
      "+---+---+\n",
      "|  1|  2|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Map schema doesnt seem to support .*\n",
    "schema = StructType().add(\"a\", MapType(StringType(), IntegerType()))\n",
    "\n",
    "df = json_to_DF(\"\"\"\n",
    "{\n",
    "  \"a\": {\n",
    "     \"b\": 1,\n",
    "     \"c\": 2\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "df.select(\"a.*\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesting columns - The struct() function or just parentheses in SQL can be used to create a new struct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|  a|  b|  c|\n",
      "+---+---+---+\n",
      "|  1|  2|  3|\n",
      "+---+---+---+\n",
      "\n",
      "+---+\n",
      "|  x|\n",
      "+---+\n",
      "|{1}|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = json_to_DF(\"\"\"\n",
    "{\n",
    "  \"a\": 1,\n",
    "  \"b\": 2,\n",
    "  \"c\": 3\n",
    "}\n",
    "\"\"\")\n",
    "df.show()\n",
    "df.select(struct(col(\"a\").alias(\"y\")).alias(\"x\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesting all columns - The star (\"*\") can also be used to include all columns in a nested struct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|      all|\n",
      "+---------+\n",
      "|{1, 2, 3}|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(struct(\"*\").alias(\"all\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a single array or map element - getItem() or square brackets (i.e. [ ]) can be used to select a single element out of an array or a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|     a|\n",
      "+------+\n",
      "|[1, 2]|\n",
      "+------+\n",
      "\n",
      "+---+\n",
      "|  x|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = json_to_DF(\"\"\"\n",
    "{\n",
    "  \"a\": [1, 2]\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "df.show()\n",
    "df.select(col(\"a\").getItem(0).alias('x')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  x|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using a map\n",
    "schema = StructType().add(\"a\", MapType(StringType(), IntegerType()))\n",
    " \n",
    "df = json_to_DF(\"\"\"\n",
    "{\n",
    "  \"a\": {\n",
    "    \"b\": 1\n",
    "  }\n",
    "}\n",
    "\"\"\", schema)\n",
    "\n",
    "df.select(col(\"a\").getItem(\"b\").alias(\"x\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a row for each array or map element - explode() can be used to create a new row for each element in an array or each key-value pair. This is similar to LATERAL VIEW EXPLODE in HiveQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|exploded|\n",
      "+--------+\n",
      "|       1|\n",
      "|       2|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = json_to_DF(\"\"\"\n",
    "{\n",
    "    \"a\":[1,2]\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "df.select(explode(\"a\").alias(\"exploded\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|               a|\n",
      "+----------------+\n",
      "|{b -> 1, c -> 2}|\n",
      "+----------------+\n",
      "\n",
      "+---+---+\n",
      "|  x|  y|\n",
      "+---+---+\n",
      "|  b|  1|\n",
      "|  c|  2|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using a map\n",
    "schema = StructType().add(\"a\", MapType(StringType(), IntegerType()))\n",
    " \n",
    "df = json_to_DF(\"\"\"\n",
    "{\n",
    "  \"a\": {\n",
    "    \"b\": 1,\n",
    "    \"c\": 2\n",
    "  }\n",
    "}\n",
    "\"\"\", schema)\n",
    "\n",
    "df.show()\n",
    "df.select(explode(\"a\").alias(\"x\",\"y\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting multiple rows into an array - collect_list() and collect_set() can be used to aggregate items into an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|     x|\n",
      "+------+\n",
      "|[1, 2]|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = json_to_DF(\"\"\"\n",
    "[{ \"x\": 1 }, { \"x\": 2 }]\n",
    "\"\"\")\n",
    " \n",
    "df.select(collect_list(\"x\").alias(\"x\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|  x|  y|\n",
      "+---+---+\n",
      "|  1|  a|\n",
      "|  2|  b|\n",
      "+---+---+\n",
      "\n",
      "+---+\n",
      "|  x|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "+---+\n",
      "\n",
      "+---+---+\n",
      "|  y|  x|\n",
      "+---+---+\n",
      "|  b|[2]|\n",
      "|  a|[1]|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using an aggregation\n",
    "df = json_to_DF(\"\"\"\n",
    "[{ \"x\": 1, \"y\": \"a\" }, { \"x\": 2, \"y\": \"b\" }]\n",
    "\"\"\")\n",
    "\n",
    "df.show()\n",
    "\n",
    "df.select(\"x\").show()\n",
    "\n",
    "# to explode both the column we have to use aggregation\n",
    "\n",
    "df.groupBy(\"y\").agg(collect_list(\"x\").alias(\"x\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting one field from each item in an array - when you use dot notation on an array we return a new array where that field has been selected from each array element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|         a|\n",
      "+----------+\n",
      "|[{1}, {2}]|\n",
      "+----------+\n",
      "\n",
      "+------+\n",
      "|     b|\n",
      "+------+\n",
      "|[1, 2]|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = json_to_DF(\"\"\"\n",
    "{\n",
    "  \"a\": [\n",
    "    {\"b\": 1},\n",
    "    {\"b\": 2}\n",
    "  ]\n",
    "}\n",
    "\"\"\")\n",
    " \n",
    "df.show()\n",
    "\n",
    "df.select(\"a.b\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert a group of columns to json - to_json() can be used to turn structs into json strings. This method is particularly useful when you would like to re-encode multiple columns into a single one when writing data out to Kafka. This method is not presently available in SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|      c|\n",
      "+-------+\n",
      "|{\"b\":1}|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = json_to_DF(\"\"\"\n",
    "{\n",
    "  \"a\": {\n",
    "    \"b\": 1\n",
    "  }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "df.select(to_json(\"a\").alias(\"c\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse a column containing json - from_json() can be used to turn a string column with json data into a struct. Then you may flatten the struct as described above to have individual columns. This method is not presently available in SQL. This method is available since Spark 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|  c|\n",
      "+---+\n",
      "|{1}|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = json_to_DF(\"\"\"\n",
    "{\n",
    "  \"a\": \"{\\\\\"b\\\\\":1}\"\n",
    "}\n",
    "\"\"\")\n",
    " \n",
    "schema = StructType().add(\"b\", IntegerType())\n",
    "df.select(from_json(\"a\", schema).alias(\"c\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sometimes you may want to leave a part of the JSON string still as JSON to avoid too much complexity in your schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|a                        |\n",
      "+-------------------------+\n",
      "|{\"b\":{\"x\":1,\"y\":{\"z\":2}}}|\n",
      "+-------------------------+\n",
      "\n",
      "+--------------+\n",
      "|             c|\n",
      "+--------------+\n",
      "|{{1, {\"z\":2}}}|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = json_to_DF(\"\"\"\n",
    "{\n",
    "  \"a\": \"{\\\\\"b\\\\\":{\\\\\"x\\\\\":1,\\\\\"y\\\\\":{\\\\\"z\\\\\":2}}}\"\n",
    "}\n",
    "\"\"\")\n",
    " \n",
    "schema = StructType().add(\"b\", StructType().add(\"x\", IntegerType())\n",
    "                            .add(\"y\", StringType()))\n",
    "\n",
    "df.show(truncate=False)\n",
    "df.select(from_json(\"a\", schema).alias(\"c\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse a set of fields from a column containing json - json_tuple() can be used to extract a fields available in a string column with json data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|      a|\n",
      "+-------+\n",
      "|{\"b\":1}|\n",
      "+-------+\n",
      "\n",
      "+---+\n",
      "|  c|\n",
      "+---+\n",
      "|  1|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = json_to_DF(\"\"\"\n",
    "{\n",
    "  \"a\": \"{\\\\\"b\\\\\":1}\"\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "df.show()\n",
    " \n",
    "df.select(json_tuple(\"a\", \"b\").alias(\"c\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse a well formed string column - regexp_extract() can be used to parse strings using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|   a|\n",
      "+----+\n",
      "|x: 1|\n",
      "|y: 2|\n",
      "+----+\n",
      "\n",
      "+---+\n",
      "|  c|\n",
      "+---+\n",
      "|  x|\n",
      "|  y|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = json_to_DF(\"\"\"\n",
    "[{ \"a\": \"x: 1\" }, { \"a\": \"y: 2\" }]\n",
    "\"\"\")\n",
    "\n",
    "df.show()\n",
    "\n",
    "df.select(regexp_extract(\"a\", \"([a-z]):\", 1).alias(\"c\")).show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "668a0c9365313c23e463277e6aba067c287d5f8af493a075d87a49f0c4e66349"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 32-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
