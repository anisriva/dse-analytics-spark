version: '3.3'
services:
  trans-seed:
    image: "anieshaz/dse-server:5.1.24-alpine"
    container_name: trans-seed
    # command: -Dcassandra.consistent.rangemovement=false
    environment:
      - DS_LICENSE=accept
      - DC=trans
      - CLUSTER_NAME=poc_cluster
      - SNITCH=GossipingPropertyFileSnitch
      - NUM_TOKENS=8
      - JVM_EXTRA_OPTS=-Xmx1g -Xms1g
    # Allow DSE to lock memory with mlock
    ports: 
      - 8983:8983
      - 9042:9042
    cap_add:
    - IPC_LOCK
    ulimits:
      memlock: -1
    volumes: 
      - $HOME/mnt/cassandra/trans-seed/cassandra:/var/lib/cassandra      
  analytics-seed:
    image: "anieshaz/dse-server:5.1.24-alpine"
    # command: -Dcassandra.consistent.rangemovement=false
    container_name: analytics-seed
    command: -k
    environment:
      - DS_LICENSE=accept
      - DC=analytics
      - SEEDS=trans-seed
      - CLUSTER_NAME=poc_cluster
      - SNITCH=GossipingPropertyFileSnitch
      - NUM_TOKENS=8
      - JVM_EXTRA_OPTS=-Xmx20g -Xms1g
      - PYTHONPATH=/opt/dse/resources/spark/python
    links:
      - trans-seed
    # Allow DSE to lock memory with mlock
    ports:
      - 8888:8888
      - 10000:10000
      - 7080-7100:7080-7100
      - 7077:7077
      - 4040-4060:4040-4060
      - 18080:18080
    cap_add:
    - IPC_LOCK
    ulimits:
      memlock: -1
    volumes: 
      - $HOME/mnt/cassandra/analytics-seed/cassandra:/var/lib/cassandra
      - $HOME/mnt/cassandra/analytics-seed/spark:/var/lib/spark
      - $HOME/resources/spark/conf/spark-defaults.conf:/opt/dse/resources/spark/conf/spark-defaults.conf
      - $HOME/resources/spark/history-spark-events:/tmp/spark-events
      - $HOME/resources/jupyter:/var/lib/spark/jupyter
  ds-studio:
    container_name: ds-studio
    image: datastax/dse-studio
    ports:
      - 9091:9091
    links:
      - trans-seed
      - analytics-seed
    environment:
      - DS_LICENSE=accept 
    cap_add:
    - IPC_LOCK
    ulimits:
      memlock: -1
    volumes: 
      - $HOME/mnt/ds-studio/:/var/lib/datastax-studio
  postgres:
      container_name: postgres_airflow_spark
      image: postgres:latest
      environment:
          - POSTGRES_USER=airflow
          - POSTGRES_PASSWORD=airflow
          - POSTGRES_DB=airflow
      volumes:
          - $HOME/mnt/airflow/pg_data:/var/lib/postgresql/data
      ports:
          - "0.0.0.0:5433:5432"
  scheduler:
      image: apache/airflow
      container_name: airflow_scheduler_spark
      restart: always
      depends_on:
          - postgres
      env_file:
          - $HOME/resources/airflow/.env
      volumes:
          - $HOME/resources/airflow/dags:/opt/airflow/dags
          - $HOME/mnt/airflow/logs:/opt/airflow/logs
      command:  >
          bash -c "
          airflow db upgrade &&
          airflow users create -u admin -f FIRST_NAME -l LAST_NAME -r Admin -e admin@example.org -p admin &&
          airflow scheduler"
  webserver:
      container_name: airflow_webserver_spark
      image: apache/airflow
      restart: on-failure
      env_file:
          - $HOME/resources/airflow/.env
      depends_on:
          - postgres
          - scheduler
      volumes:
          - $HOME/resources/airflow/dags:/opt/airflow/dags
          - $HOME/mnt/airflow/logs:/opt/airflow/logs
      ports:
          - "0.0.0.0:8080:8080"
      command:  >
          bash -c "airflow webserver"
  # sandbox:
  #     image: anieshaz/spark-client:1.0
  #     container_name: sandbox    
  #     # volumes:
  #     #     - C:\Work\workspace\spark-2.0.2-bin-without-hadoop:/spark
  #     command:  >
  #         bash -c "sleep infinity"